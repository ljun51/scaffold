# Hadoop

## 生态

### Hudi-0.14.1 下一代流数据湖平台

特性：
* 可插拔索引机制支持快速 Upsert/Delete
* 支持增量拉取表变更以进行处理
* 支持事物提交及回滚，并法控制
* 支持 Spark、Presto、Trino、Hive、Flink 等引擎的 SQL 读写
* 自动管理小文件，数据聚簇、压缩、清理
* 流式摄入，内置 CDC 源和工具
* 向后兼容的方式实现表结构变更的支持

使用场景：
* 近实时写入
* 近实时分析
* 增量 pipline

### Kylin-5.0
### Hive 数据仓库
### Sqoop （已退役）数据库ETL
### HBase 分布式数据库
### Phoenix 
Phoenix是HBase的开源SQL皮肤。可以使用标准JDBC API代替HBase客户端API来创建表，插入数据和查询HBase数据。

Phoenix特点

* 支持标准化SQL，可以是hbase处理更加灵活复杂事务的能力。
* 完美支持Hbase二级索引创建。
* 容易集成：如Spark，Hive，Pig，Flume和Map Reduce。

### Flink 实时计算框架
### Spark 内存计算框架
### YARN 资源管理系统
### HDFS 分布式文件系统
  
HDFS的优点（HDFS适合的场景）
1. 高容错性。数据自动保存多个副本，HDFS通过增加多个副本的形式，提高了HDFS文件系统的容错性；某一个副本丢失以后可以自动恢复。
2. 适合大数据处理。能够处理GB、TB、甚至PB级别的数据规模；能够处理百万规模以上的文件数量；能够处理10000个以上节点的集群规模。
3. 流式文件访问。数据文件只能一次写入，多次读取，只能追加，不能修改；HDFS能保证数据的简单一致性。
4. 可构建在廉价的机器上。HDFS通过多副本机制，提高了整体系统的可靠性；HDFS提供了容错和恢复机制。比如某一个副本丢失，可以通过其他副本来恢复。保证了数据的安全性和系统的可靠性。

HDFS的缺点（HDFS不适合的场景）
1. 不适合低延时数据访问。比如ms级别的数据响应时间，这种场景HDFS是很难做到的。HDFS更适合高吞吐率的场景，即在某一时间内写入大量的数据。
2. 不适合大量小文件的存储。如果有大量小文件需要存储，这些小文件的元数据信息的存储会占用NameNode大量的内存空间。这样是不可取的，因为NameNode的内存总是有限的；如果小文件存储的寻道时间超过文件数据的读取时间，这样也是不行的，它违反了HDFS大数据块的设计目标。
3. 不适合并发写入、文件随机修改。一个文件只能有一个写操作，不允许多个线程同时进行写操作；仅支持数据的append（追加）操作，不支持文件的随机修改。

### Kafka 消息队列
### Flume 日志采集
### Zookeeper 分布式协调服务