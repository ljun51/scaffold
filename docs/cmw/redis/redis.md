# redis

## 快速开始
```shell
docker network create redis_network
```

```shell
docker run -d \
--name redis-server \
--restart=always \
-p 6379:6379 \
-v ./cmw/redis/redis.conf:/etc/redis/redis.conf \
-v ./cmw/redis/data:/data \
--network redis_network \
redis:7.2.4 \
redis-server /etc/redis/redis.conf --appendonly yes
```

客户端连接：

```shell
docker run -it --network redis_network --rm redis redis-cli -a foobar -h redis-server
```

## 为什么是 Reids？
Redis 是一种支持 key-alue 等多种数据结构的存储系统。可用于缓存、发布/订阅、高速队列等业务场景。
提供字符串、哈希、列表、队列、集合结构直接存储，基于内存，可持久化。

* 读写性能优异
  * Redis能读的速度是110000次/s,写的速度是81000次/s。
* 数据类型丰富
  * Redis支持 String、List、Set、Hash、Zset 数据类型操作。
* 原子性
  * Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。
* 丰富的特性
  * Redis支持 publish/subscribe, 通知, key 过期等特性。
* 持久化
  * Redis支持RDB, AOF等持久化方式
* 发布订阅
  * Redis支持发布/订阅模式
* 分布式
  * Redis Cluster

## 为什么Redis 是单线程的以及为什么这么快？
* redis完全基于内存,绝大部分请求是纯粹的内存操作,非常快速
* 数据结构简单,对数据操作也简单,redis中的数据结构是专门进行设计的
* 采用单线程模型, 避免了不必要的上下文切换和竞争条件, 也不存在多线程或者多线程切换而消耗CPU, 不用考虑各种锁的问题, 不存在加锁, 释放锁的操作, 没有因为可能出现死锁而导致性能消耗
* 使用了多路IO复用模型,非阻塞IO
* 使用底层模型不同,它们之间底层实现方式及与客户端之间的 通信的应用协议不一样,Redis直接构建了自己的VM机制,因为一般的系统调用系统函数的话,会浪费一定的时间去移动和请求

## 数据类型
* 5种基础数据类型，分别是：String、List、Set、Hash、Zset。
  * String：可以是字符串、整数或浮点数，对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作；
  * List：可以是一个链表，链表上的每个节点都包含一个字符串，对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素；
  * Set：可以包含字符串的无序集合，字符串的集合，基础的方法有：是否存在、添加、获取、删除；还包含计算交集、并集、差集等；
  * Hash：包含键值对的无序散列表，包含方法有添加、获取、删除单个元素；
  * Zset：和散列一样，用于存储键值对，字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素。
* 3种特殊的数据类型，分别是 HyperLogLogs（基数统计）、Bitmaps (位图) 和 geospatial（地理位置）。

## 容量
Redis 一个字符串类型的值能存储最大容量是多少：512M

## 过期策略
在单机版Redis中，存在两种删除策略：
* 惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。
* 定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。
 
在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。

Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。#

## 内存淘汰算法
Redis共支持八种淘汰策略，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random 和 allkeys-lfu 策略。

怎么理解呢？主要看分三类看：
* 不淘汰 
  * noeviction（v4.0后默认的）
* 对设置了过期时间的数据中进行淘汰 
  * 随机：volatile-random
  * ttl：volatile-ttl
  * lru：volatile-lru
  * lfu：volatile-lfu
* 全部数据进行淘汰 
  * 随机：allkeys-random
  * lru：allkeys-lru
  * lfu：allkeys-lfu

`LRU` 算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。

Redis 优化的 LRU 算法实现：Redis会记录每个数据的最近一次被访问的时间戳。在Redis在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。通过随机读取待删除集合，可以让Redis不用维护一个巨大的链表，也不用操作链表，进而提升性能。

`LFU` 算法：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 

Redis 优化的 LFU 算法实现：当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。

Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样在访问快速的情况下，如果每次被访问就将访问次数加一，很快某条数据就达到最大值255，可能很多数据都是255，那么退化成LRU算法了。所以Redis为了解决这个问题，实现了一个更优的计数规则，并可以通过配置项，来控制计数器增加的速度。

Redis的内存用完了会发生什么？

如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。

## Redis如何做内存优化？
* 缩减键值对象: 缩减键（key）和值（value）的长度
  * key长度：如在设计键时，在完整描述业务情况下，键值越短越好。
  * value长度：值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入Redis。首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。以JAVA为例，内置的序列化方式无论从速度还是压缩比都不尽如人意，这时可以选择更高效的序列化工具，如: protostuff，kryo等。
* 共享对象池
  * 对象共享池指Redis内部维护[0-9999]的整数对象池。创建大量的整数类型redisObject存在内存开销，每个redisObject内部结构至少占16字节，甚至超过了整数自身空间消耗。所以Redis内存维护一个[0-9999]的整数对象池，用于节约内存。除了整数值对象，其他类型如list,hash,set,zset内部元素也可以使用整数对象池。因此开发中在满足需求的前提下，尽量使用整数对象以节省内存。
* 字符串优化
* 编码优化
* 控制key的数量

## 管道
Redis 管道技术是一种批处理技术，允许客户端在服务端未响应时，连续向服务端发送多个 Redis 命令请求，并最终一次性读取所有服务端的响应。这有助于提高 Redis 的性能，特别在高并发场景下。

## 事物
Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。

Redis事务相关命令：
* `MULTI` 开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。
* `EXEC` 执行事务中的所有操作命令。
* `DISCARD` 取消事务，放弃执行事务块中的所有命令。
* `WATCH` 监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。
* `UNWATCH` 取消WATCH对所有key的监视。

为什么 Redis 不支持回滚？

以下是这种做法的优点：
* Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。
* 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。

## 持久化
Redis 作为一款被广泛应用的内存数据库，其持久化机制是确保数据安全和稳定性的关键所在。让我们深入了解一下 Redis 的持久化方式：
1. `RDB（Redis DataBase）`：RDB 是 Redis 默认的持久化方式。它将 Redis 在内存中的数据写入到硬盘中，生成一个快照文件。这个快照文件是一个经过压缩的二进制文件，包含了 Redis 在某个时间点内的所有数据。RDB 的优点是快速、简单，适用于大规模数据备份和恢复。然而，它也有缺点，例如数据可能会丢失，因为 Redis 只会在指定的时间点生成快照文件。如果在快照文件生成之后，但在下一次快照文件生成之前服务器宕机，那么这期间的数据就会丢失。
2. `AOF（Append Only File）`：AOF 则是以追加的方式记录 Redis 执行的每一条写命令。它将所有写操作追加到一个日志文件中。在服务器重启时，只需将这些写命令从头到尾再执行一遍，就可以实现数据恢复。AOF 的优点是数据更加持久，但相对于 RDB，它的文件通常会更大。

RDB 持久化可以通过以下两种方式触发：
* 手动方式：
  * 使用 `SAVE` 命令：这会阻塞 Redis 服务器进程，直到 RDB 文件创建完毕为止。
  * 使用 `BGSAVE` 命令：这会在后台 fork 一个子进程来生成快照文件，不会阻塞服务器进程。
* 自动方式：
  * 在配置文件中设置 save 选项，满足条件时自动触发 BGSAVE 命令。例如，可以配置多个条件，只要其中任何一个满足，就会触发 BGSAVE。例如：
```conf
    save 900 1
    save 300 10
    save 60 10000
```
这表示只要满足其中一个条件，就会执行 BGSAVE 命令。

Redis 使用操作系统的写时复制（Copy On Write，即 COW）机制来实现 RDB 持久化。这允许父子进程共享内存，减少内存占用，并避免不必要的数据复制。通过这种方式，Redis 可以高效地执行 RDB 持久化操作，而不会对运行过程中的性能造成太大影响。

## 分布式锁
    
    分布式锁其实就是，控制分布式系统不同进程共同访问共享资源的一种锁的实现。如果不同的系统或同一个系统的不同主机之间共享了某个临界资源，往往需要互斥来防止彼此干扰，以保证一致性。

* 互斥性: 任意时刻，只有一个客户端能持有锁。
* 锁超时释放：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。
* 可重入性:一个线程如果获取了锁之后,可以再次对其请求加锁。
* 高性能和高可用：加锁和解锁需要开销尽可能低，同时也要保证高可用，避免分布式锁失效。
* 安全性：锁只能被持有的客户端删除，不能被其他客户端删除

提到Redis的分布式锁，很多小伙伴马上就会想到`setnx + expire`命令。即先用setnx来抢锁，如果抢到之后，再用expire给锁设置一个过期时间，防止锁忘记了释放。

    SETNX 是SET IF NOT EXISTS的简写。命令格式是SETNX key value，如果 key不存在，则SETNX成功返回1，如果这个key已经存在了，则返回0。

在分布式锁的场景中，主要用在比如秒杀系统等。

## 集群
### 主从复制
Redis 的主从复制是一项关键功能，用于实现数据的备份、故障恢复和负载均衡。让我们深入了解一下主从复制的概念、原理和实现步骤：

概述
* 主从复制是将一台 Redis 服务器的数据复制到其他 Redis 服务器的过程。
* 主节点（master）是数据源，从节点（slave）接收主节点的数据。
* 数据复制是单向的，只能由主节点到从节点。
* 默认情况下，每台 Redis 服务器都是主节点，但一个主节点可以有多个从节点。

作用
* 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
* 故障恢复：当主节点出现问题时，从节点可以接管服务，实现快速的故障恢复。
* 负载均衡：通过读写分离，主节点提供写服务，从节点提供读服务，分担服务器负载。
* 高可用基石：主从复制是 Redis 高可用的基础。

CAP 原理
* CAP 原理是现代分布式系统的理论基石。
* C - 一致性，A - 可用性，P - 分区容忍性。
* Redis 主从同步满足 可用性，但不满足严格的 一致性。

实现原理
* 设置主节点地址和端口：从节点设置需要同步的主服务器信息。
* 建立套接字连接：从节点向主节点建立 socket 连接。
* 发送 PING 命令：检查连接是否可用，主节点是否能处理请求。
* 身份验证：如果设置了密码，从节点向主节点进行身份验证。
* 同步：将从节点的数据库状态更新成主节点当前的状态。
* 命令传播：主节点将写命令发送给从节点，保持数据一致性。

主从复制是 Redis 高可用的基础，确保数据的安全和稳定性。

### 哨兵机制
Redis 的哨兵机制是一项关键功能，用于实现 Redis 集群的高可用性。让我们深入了解一下哨兵机制的概念、原理和实现步骤：

概述：
* 哨兵是运行在特殊模式下的 Redis 进程，专注于监控和管理主从节点的运行状态。
* 哨兵系统由一个或多个哨兵实例组成，形成一个哨兵集群。
* 哨兵监控主节点和从节点，并在主节点故障时自动执行故障转移操作。

功能：
* 监控：哨兵系统周期性地检测主从节点的运行状态，确保它们正常运行。
* 故障转移：当主节点挂掉时，哨兵从从节点中选取一个作为新的主节点，保证服务的高可用。
* 通知：哨兵将主从节点的相关信息通知给客户端，确保客户端数据始终为最新状态。

监控流程：
* 哨兵周期性地向主从节点发送 PING 命令，检测它们是否存活。
* 如果节点在规定时间内响应，判定为存活；否则判定为下线。
* 如果主节点下线，哨兵进行故障转移，选举一个从节点作为新的主节点。

通信方式：
* 哨兵之间通过 发布/订阅模式 进行通信。
* 哨兵不直接连接其他哨兵，而是先与主库建立连接，然后通过频道发布自己的信息，让其他哨兵获取到。

主观下线和客观下线：
* 主观下线是哨兵自行判断主库是否故障。
* 客观下线需要多数哨兵认同，触发主从切换。

哨兵机制确保了 Redis 集群的可用性和稳定性。

## 缓存
### 缓存穿透
缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

解决方案
* 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
* 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击；
* 布隆过滤器，bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。

### 缓存击穿
缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

解决方案
* 设置热点数据永远不过期。
* 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些 服务 不可用时候，进行熔断，快速失败返回机制。
* 加互斥锁

### 缓存雪朋
缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

解决方案
* 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
* 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。
* 设置热点数据永远不过期。

## Redis性能问题有哪些，如何分析定位解决？
* 看延迟
60 秒内的最大响应延迟：
```shell    
$ redis-cli -h 127.0.0.1 -p 6379 --intrinsic-latency 60
Max latency so far: 1 microseconds.
Max latency so far: 15 microseconds.
Max latency so far: 17 microseconds.
Max latency so far: 18 microseconds.
Max latency so far: 31 microseconds.
Max latency so far: 32 microseconds.
Max latency so far: 59 microseconds.
Max latency so far: 72 microseconds.
 
1428669267 total runs (avg latency: 0.0420 microseconds / 42.00 nanoseconds per run).
Worst run took 1429x longer than the average latency.
```
* 慢日志（slowlog）
* 大对象（bigkey）

## Redis单线程模型？ 
在6.0之前如何提高多核CPU的利用率？可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。

## Redis6.0之前的版本真的是单线程的吗？
Redis在处理客户端请求时,包括获取(socket读)、解析、执行、内容返回(socket写)等都是由一个顺序串行的主线程执行的,这就是所谓的 单线程.单如果严格讲,从Redis4.0之后并不是单线程,除了主线程之外,它也有后台线程在处理一些较为缓慢的操作,例如 清理脏数据, 无用链接的释放, 大key的删除, 数据持久化bgsave,bgrewriteaof等,都是在主线程之外的子线程单独执行的.

## Redis6.0之前为什么一直不用多线程?
官方曾做过类似问题的回复：使用Redis时，几乎不存在CPU成为瓶颈的情况， Redis主要受限于内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理100万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。

使用了单线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。Redis通过AE事件模型以及IO多路复用等技术，处理性能非常高，因此没有必要使用多线程。单线程机制使得 Redis 内部实现的复杂度大大降低，Hash 的惰性 Rehash、Lpush 等等 “线程不安全” 的命令都可以无锁进行。

## Redis6.0为什么要引入多线程呢？
Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理80,000到100,000 QPS，这也是Redis处理的极限了，对于80%的公司来说，单线程的Redis已经足够使用了。但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的QPS。常见的解决方案是在分布式架构中对数据进行分区并采用多个服务器，但该方案有非常大的缺点，例如要管理的Redis服务器太多，维护代价大；某些适用于单个Redis服务器的命令不适用于数据分区；数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变得更加复杂等等。从Redis自身角度来说，因为读写网络的read/write系统调用占用了Redis执行期间大部分CPU时间，瓶颈主要在于网络的 IO 消耗, 优化主要有两个方向:提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式使用多线程充分利用多核，典型的实现比如 Memcached协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以总结起来，redis支持多线程主要就是两个原因：可以充分利用服务器 CPU 资源，目前主线程只能利用一个核多线程任务可以分摊 Redis 同步 IO 读写负荷

## Redis6.0默认是否开启了多线程？
Redis6.0的多线程默认是禁用的，只使用主线程。如需开启需要修改redis.conf配置文件：io-threads-do-reads yes

## Redis6.0多线程开启时，线程数如何设置？
开启多线程后，还需要设置线程数，否则是不生效的。同样修改redis.conf配置文件 io-threads 4

关于线程数的设置，官方有一个建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。还需要注意的是，线程数并不是越大越好，官方认为超过了8个基本就没什么意义了。

## Redis6.0多线程的实现机制？
核心思路是，将主线程的IO读写任务拆分出来给一组独立的线程执行，使得多个 socket 的读写可以并行化
* 主线程负责接收建立连接的请求,获取socket放到全局等待处理队列
* 主线程处理完读事件之后,通过Round Robin将这些连接分配给IO线程(并不会等待队列满)
* 主线程阻塞等待IO线程读取socket完毕
* 主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行
* 主线程阻塞等待IO线程将数据回写socket完毕
* 解除绑定,清空等待队列

IO线程有如下特点:
* IO线程要么同时在读socket，要么同时在写，不会同时读或写
* IO线程只负责读写socket解析命令，不负责命令处理（主线程串行执行命令）

## 开启多线程后，是否会存在线程并发安全问题？
Redis的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行,因此不存在线程的并发安全问题。